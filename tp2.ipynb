{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidade Federal de Minas Gerais\n",
    "\n",
    "Departamento de Ciência da Computação\n",
    "\n",
    "Bacharelado em Ciência da Computação\n",
    "\n",
    "Introdução a Computação Visual – 2017/1\n",
    "\n",
    "Professor: Erickson R. Nascimento e William Robson Schwartz\n",
    "\n",
    "# Trabalho Pŕatico 2 - Realidade Aumentada\n",
    "\n",
    "### Alison de Oliveira Souza - 2012049316"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Calibração da câmera\n",
    "\n",
    "Para calibrar a câmera usei o código calibration.cpp disponibilizado na pasta samples/cpp do OpenCV 3.1.0.\n",
    "\n",
    "Compilei tal código da seguinte maneira:\n",
    "\n",
    "g++ -Iusr/include/opencv2 calibration.cpp $(pkg-config opencv --libs) -o calibration\n",
    "\n",
    "Após compilar, executei o binário calibration da seguinte maneira:\n",
    "\n",
    "./calibration -w=6 -h=8 -s=0.03 -n=8 -V entrada.avi -o=intrinsic.yml -zt\n",
    "\n",
    "Com isso, foi gerado o arquivo intrinsic.yml com a seguinte saída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%YAML:1.0\n",
    "calibration_time: \"ter 30 mai 2017 14:33:09 -03\"\n",
    "image_width: 640\n",
    "image_height: 480\n",
    "board_width: 6\n",
    "board_height: 8\n",
    "square_size: 2.9999999329447746e-02\n",
    "aspectRatio: 1.\n",
    "flags: 10\n",
    "camera_matrix: !!opencv-matrix\n",
    "   rows: 3\n",
    "   cols: 3\n",
    "   dt: d\n",
    "   data: [ 5.8841583430397554e+02, 0., 3.0732260409727314e+02, 0.,\n",
    "       5.8841583430397554e+02, 2.2350170630520270e+02, 0., 0., 1. ]\n",
    "distortion_coefficients: !!opencv-matrix\n",
    "   rows: 5\n",
    "   cols: 1\n",
    "   dt: d\n",
    "   data: [ 4.3817979965505918e-02, 2.8013203741313847e-01, 0., 0.,\n",
    "       1.3472499999780172e+01 ]\n",
    "avg_reprojection_error: 2.5354900956128007e-01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: Detecção e Localização dos alvos\n",
    "Para essa etapa utilizei os conceitos e funções pré-definidas no link:\n",
    "\n",
    "https://rdmilligan.wordpress.com/2015/07/19/glyph-recognition-using-opencv-and-python/\n",
    "\n",
    "Essas funções ajudam na detecção de padrões binários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias para o trabalho.\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###############################################################\n",
    "##                     FUNÇÕES AUXILIARES                    ##\n",
    "###############################################################\n",
    "def order_points(points):\n",
    " \n",
    "    s = points.sum(axis=1)\n",
    "    diff = np.diff(points, axis=1)\n",
    "     \n",
    "    ordered_points = np.zeros((4,2), dtype=\"float32\")\n",
    " \n",
    "    ordered_points[0] = points[np.argmin(s)]\n",
    "    ordered_points[2] = points[np.argmax(s)]\n",
    "    ordered_points[1] = points[np.argmin(diff)]\n",
    "    ordered_points[3] = points[np.argmax(diff)]\n",
    " \n",
    "    return ordered_points\n",
    " \n",
    "def max_width_height(points):\n",
    " \n",
    "    (tl, tr, br, bl) = points\n",
    " \n",
    "    top_width = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    bottom_width = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    max_width = max(int(top_width), int(bottom_width))\n",
    " \n",
    "    left_height = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    right_height = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    max_height = max(int(left_height), int(right_height))\n",
    " \n",
    "    return (max_width,max_height)\n",
    " \n",
    "def topdown_points(max_width, max_height):\n",
    "    return np.array([\n",
    "        [0, 0],\n",
    "        [max_width-1, 0],\n",
    "        [max_width-1, max_height-1],\n",
    "        [0, max_height-1]], dtype=\"float32\")\n",
    " \n",
    "def get_topdown_quad(image, src):\n",
    " \n",
    "    # src and dst points\n",
    "    src = order_points(src)\n",
    " \n",
    "    (max_width,max_height) = max_width_height(src)\n",
    "    dst = topdown_points(max_width, max_height)\n",
    "  \n",
    "    # warp perspective\n",
    "    matrix = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(image, matrix, max_width_height(src))\n",
    " \n",
    "    # return top-down quad\n",
    "    return warped\n",
    "\n",
    "def get_glyph_pattern(image, black_threshold, white_threshold):\n",
    " \n",
    "    # collect pixel from each cell (left to right, top to bottom)\n",
    "    cells = []\n",
    "     \n",
    "    cell_half_width = int(round(image.shape[1] / 14.0))\n",
    "    cell_half_height = int(round(image.shape[0] / 14.0))\n",
    " \n",
    "    row1 = cell_half_height*3\n",
    "    row2 = cell_half_height*5\n",
    "    row3 = cell_half_height*7\n",
    "    row4 = cell_half_height*9\n",
    "    row5 = cell_half_height*11\n",
    "    col1 = cell_half_width*3\n",
    "    col2 = cell_half_width*5\n",
    "    col3 = cell_half_width*7\n",
    "    col4 = cell_half_width*9\n",
    "    col5 = cell_half_width*11\n",
    " \n",
    "    cells.append(image[row1, col1])\n",
    "    cells.append(image[row1, col2])\n",
    "    cells.append(image[row1, col3])\n",
    "    cells.append(image[row1, col4])\n",
    "    cells.append(image[row1, col5])\n",
    "    cells.append(image[row2, col1])\n",
    "    cells.append(image[row2, col2])\n",
    "    cells.append(image[row2, col3])\n",
    "    cells.append(image[row2, col4])\n",
    "    cells.append(image[row2, col5])\n",
    "    cells.append(image[row3, col1])\n",
    "    cells.append(image[row3, col2])\n",
    "    cells.append(image[row3, col3])\n",
    "    cells.append(image[row3, col4])\n",
    "    cells.append(image[row3, col5])\n",
    "    cells.append(image[row4, col1])\n",
    "    cells.append(image[row4, col2])\n",
    "    cells.append(image[row4, col3])\n",
    "    cells.append(image[row4, col4])\n",
    "    cells.append(image[row4, col5])\n",
    "    cells.append(image[row5, col1])\n",
    "    cells.append(image[row5, col2])\n",
    "    cells.append(image[row5, col3])\n",
    "    cells.append(image[row5, col4])\n",
    "    cells.append(image[row5, col5])\n",
    " \n",
    "    # threshold pixels to either black or white\n",
    "    for idx, val in enumerate(cells):\n",
    "        if val < black_threshold:\n",
    "            cells[idx] = 0\n",
    "        elif val > white_threshold:\n",
    "            cells[idx] = 1\n",
    "        else:\n",
    "            return None\n",
    " \n",
    "    return cells\n",
    " \n",
    "def resize_image(image, new_size):\n",
    "    ratio = new_size / image.shape[1]\n",
    "    return cv2.resize(image,(int(new_size),int(image.shape[0]*ratio)))\n",
    " \n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w / 2, h / 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "SHAPE_RESIZE = 100.0\n",
    "BLACK_THRESHOLD = 127\n",
    "WHITE_THRESHOLD = 128\n",
    "\n",
    "# Lendo imagem alvo, ou seja, padrão que será buscado no vídeo.\n",
    "img = cv2.imread('alvo.jpg')\n",
    "\n",
    "# Aplicando imagem em escala de cinza e eliminando ruídos borrando a imagem.\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlurred = cv2.GaussianBlur(imgGray, (7, 7), 0)\n",
    "\n",
    "# Salva o padrão a ser buscado na variável img_pattern\n",
    "img_pattern = get_glyph_pattern(imgBlurred, BLACK_THRESHOLD, WHITE_THRESHOLD)\n",
    "\n",
    "# Abrindo o vídeo de entrada.\n",
    "camera = cv2.VideoCapture('entrada.avi')\n",
    "\n",
    "# Cria vídeo de saída.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "# Loop para iterar sobre cada frame do vídeo.\n",
    "while True:\n",
    "    # Lendo o frame atual e salvando o status da leitura na flag readed.\n",
    "    (readed, frame) = camera.read()\n",
    "\n",
    "    # Verificado se há mais frames no vídeo. Caso tenha chegado\n",
    "    # ao fim do vídeo, encerro o loop de iteração sobre frames.\n",
    "    if not readed:\n",
    "        break\n",
    " \n",
    "    # Convertendo o frame em grayscale, borrando o frame para remover excesso de\n",
    "    # ruídos (e pequenas bordas), e detectando bordas.\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "    edged = cv2.Canny(blurred, 100, 200)\n",
    "    \n",
    "    # Encontra os contornos nas imagens de bordas.\n",
    "    (image, countours, _) = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    countours = sorted(countours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # Loop de iteração sobre os contornos.\n",
    "    for c in countours:\n",
    "        # Escolhe os contornos com mais de 40 pontos, eliminando bordas pequenas.\n",
    "        if len(c) > 40:\n",
    "            # Aproximação Poligonal dos contornos.\n",
    "            perimeter = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.01 * perimeter, True)\n",
    "            \n",
    "            # Aproveitando apenas contornos que são aproximadamente retangulares.\n",
    "            if len(approx) == 4:\n",
    "                \n",
    "                # Função que rotaciona os quadrilateros encontrados para facilitar\n",
    "                # identificação dos alvos.\n",
    "                topdown_quad = get_topdown_quad(blurred, approx.reshape(4,2))\n",
    "                \n",
    "                # Redimensiona o objeto e verifica se há um pixel escuro dentro da borda.\n",
    "                # Se não houver, nenhum então descartamos esse objeto, pois nosso alvo tem\n",
    "                # pontos pretos. Isso basicamente descarta os quadrados brancos dentro do padrão.\n",
    "                resized_shape = resize_image(topdown_quad, SHAPE_RESIZE)\n",
    "                if resized_shape[7, 7] > BLACK_THRESHOLD:\n",
    "                    continue\n",
    "                \n",
    "                # Flag que indica que encontramos o alvo.\n",
    "                glyph_found = False\n",
    "                \n",
    "                # Realiza 4 buscas de padrão, uma de cada lado do alvo, rotacionando ele 90° por vez.\n",
    "                for i in range(4):\n",
    "                    glyph_pattern = get_glyph_pattern(resized_shape, BLACK_THRESHOLD, WHITE_THRESHOLD)\n",
    "                    \n",
    "                    if glyph_pattern == img_pattern:\n",
    "                        glyph_found = True\n",
    "                        break\n",
    "                        \n",
    "                    resized_shape = rotate_image(resized_shape, 90)\n",
    "                \n",
    "                # Se encontrou o padrão.\n",
    "                if glyph_found:\n",
    "                    # Hora de desenhar o quadrado sobre o alvo\n",
    "                    # e por o pikachu.\n",
    "                    #print \"ENTROU NO IF\"\n",
    "                    # LUGAR CERTO PARA O DRAWCONTOURS, PORÉM NÃO FUNCIONA!!!\n",
    "                    #cv2.drawContours(frame, approx, -1, (0, 0, 255), 4)\n",
    "                    break\n",
    "                \n",
    "                # Lugar errado para a drawContours. Aqui ela marca qualquer polígono.\n",
    "                cv2.drawContours(frame, [approx], -1, (0, 0, 255), 4)\n",
    "                cv2.imshow('Frame', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "                \n",
    "                cv2.imshow('Bordas', image)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "    out.write(frame)\n",
    "\n",
    "camera.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Não consegui realizar a marcação correta em volta dos padrões. Dentro do if que verifica se o padrão foi encontrado, há uma chamada para a função drawContours que não funciona. Fiz um teste colocando um print dentro do if, para verificar se o fluxo de execução está realmente passando por lá, e a frase ENTROU NO IF é printada, mostrando que o fluxo de execução passa pelo if, várias vezes inclusive. Mas por algum motivo, que não conseguir descobrir qual, o contorno dos padrões não é exibido na tela.\n",
    "\n",
    "Ao colocar a mesma função drawContours do lado de fora do if, a função desenha os contornos, mas não apenas nos padrões, e sim em qualquer polígono com aproximação com 4 pontos, incluindo alguns quadrados do tabuleiro. Por esse motivo, decedi enviar o  vídeo que marca todos os contornos, mesmo que errados. Caso queira ver a execução que deveria funcionar, basta comentar a linha onde há a função cv2.drawContours indicada como errada e descomentar a linha marcada como correta logo acima.\n",
    "\n",
    "Por esse e outros motivos não consegui ir adiante. Instalar e configurar o OpenCV e Jupyter-Notebook para fazer esse trabalho foi algo extremamente trabalhoso. Tive que compilar o OpenCV no Linux pelo menos 3 vezes, isso depois de ter instalado pelo menos 2 versões diferentes (3.1 e 3.2) no Windows, ambas com problemas ao ler o vídeo, por falta de integração com o ffmpeg.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
